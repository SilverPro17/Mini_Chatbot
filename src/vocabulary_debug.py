#!/usr/bin/env python3
"""
Debug especÃ­fico para entender por que 'brigadeiro' nÃ£o funciona
"""

import os
import re
from sklearn.feature_extraction.text import TfidfVectorizer

def load_text_content():
    """Carrega conteÃºdo dos arquivos"""
    print("ğŸ“š Carregando conteÃºdo dos arquivos...")
    
    files = [
        "data/texts/receitas_brasileiras.txt",
        "data/texts/ingredientes_brasileiros.txt",
        "data/texts/tecnicas_culinarias.txt"
    ]
    
    all_content = ""
    
    for file_path in files:
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()
                all_content += content + "\n"
                print(f"âœ… {file_path}: {len(content)} caracteres")
    
    return all_content

def search_word_in_content(content, word):
    """Procura uma palavra especÃ­fica no conteÃºdo"""
    print(f"\nğŸ” Procurando '{word}' no conteÃºdo...")
    
    # Busca case-insensitive
    matches = re.finditer(word.lower(), content.lower())
    positions = list(matches)
    
    print(f"ğŸ“Š Encontradas {len(positions)} ocorrÃªncias de '{word}'")
    
    for i, match in enumerate(positions[:3]):  # Mostra as primeiras 3
        start = max(0, match.start() - 50)
        end = min(len(content), match.end() + 50)
        context = content[start:end].replace('\n', ' ')
        print(f"{i+1}. ...{context}...")

def test_vectorizer_steps():
    """Testa cada passo do vectorizer"""
    print("\nğŸ”§ Testando passos do vectorizer...")
    
    # Carrega conteÃºdo
    content = load_text_content()
    
    # Procura brigadeiro no texto original
    search_word_in_content(content, "brigadeiro")
    
    # Divide em seÃ§Ãµes
    sections = content.split('===')
    brigadeiro_sections = []
    
    print(f"\nğŸ“„ Total de seÃ§Ãµes: {len(sections)}")
    
    for i, section in enumerate(sections):
        if 'brigadeiro' in section.lower():
            brigadeiro_sections.append((i, section.strip()))
            print(f"âœ… SeÃ§Ã£o {i} contÃ©m 'brigadeiro'")
    
    if not brigadeiro_sections:
        print("âŒ Nenhuma seÃ§Ã£o contÃ©m 'brigadeiro'!")
        return
    
    # Testa preprocessamento
    print(f"\nğŸ”§ Testando preprocessamento da primeira seÃ§Ã£o com brigadeiro...")
    section_content = brigadeiro_sections[0][1]
    print(f"ğŸ“ SeÃ§Ã£o original: {section_content[:200]}...")
    
    # Preprocessamento simples
    processed = section_content.lower()
    processed = re.sub(r'[^\w\sÃ¡Ã Ã¢Ã£Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§]', ' ', processed)
    processed = re.sub(r'\s+', ' ', processed)
    
    print(f"ğŸ“ SeÃ§Ã£o processada: {processed[:200]}...")
    
    # Verifica se brigadeiro ainda estÃ¡ lÃ¡
    if 'brigadeiro' in processed:
        print("âœ… 'brigadeiro' ainda estÃ¡ presente apÃ³s preprocessamento")
    else:
        print("âŒ 'brigadeiro' foi removido no preprocessamento!")
    
    # Testa TF-IDF
    print(f"\nğŸ—ƒï¸ Testando TF-IDF...")
    
    # Todas as seÃ§Ãµes processadas
    all_sections = []
    for section in sections:
        if len(section.strip()) > 50:
            processed = section.lower()
            processed = re.sub(r'[^\w\sÃ¡Ã Ã¢Ã£Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§]', ' ', processed)
            processed = re.sub(r'\s+', ' ', processed)
            all_sections.append(processed)
    
    print(f"ğŸ“Š SeÃ§Ãµes para TF-IDF: {len(all_sections)}")
    
    # Cria vectorizer simples
    vectorizer = TfidfVectorizer(
        max_features=1000,
        lowercase=True,
        stop_words=None,  # SEM stop words para testar
        token_pattern=r'[a-zÃ¡Ã Ã¢Ã£Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§]+',
        min_df=1
    )
    
    # Treina
    try:
        tfidf_matrix = vectorizer.fit_transform(all_sections)
        print(f"âœ… TF-IDF criado: {tfidf_matrix.shape}")
        print(f"ğŸ“– VocabulÃ¡rio: {len(vectorizer.vocabulary_)} palavras")
        
        # Verifica se brigadeiro estÃ¡ no vocabulÃ¡rio
        if 'brigadeiro' in vectorizer.vocabulary_:
            idx = vectorizer.vocabulary_['brigadeiro']
            print(f"âœ… 'brigadeiro' encontrado no vocabulÃ¡rio (Ã­ndice {idx})")
            
            # Testa query
            query_vector = vectorizer.transform(['brigadeiro'])
            print(f"âœ… Query 'brigadeiro' transformada: {query_vector.shape}")
            
            # Calcula similaridades
            from sklearn.metrics.pairwise import cosine_similarity
            similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()
            max_sim = max(similarities)
            print(f"ğŸ“Š Similaridade mÃ¡xima: {max_sim:.4f}")
            
            if max_sim > 0:
                best_idx = similarities.argmax()
                print(f"ğŸ¯ Melhor match na seÃ§Ã£o {best_idx}")
                print(f"ğŸ“ ConteÃºdo: {all_sections[best_idx][:100]}...")
            
        else:
            print("âŒ 'brigadeiro' NÃƒO estÃ¡ no vocabulÃ¡rio!")
            
            # Mostra algumas palavras do vocabulÃ¡rio
            vocab_sample = list(vectorizer.vocabulary_.keys())[:20]
            print(f"ğŸ“– Amostra do vocabulÃ¡rio: {vocab_sample}")
            
            # Procura palavras similares
            similar_words = [word for word in vectorizer.vocabulary_.keys() if 'brig' in word or 'doce' in word]
            print(f"ğŸ” Palavras relacionadas: {similar_words}")
        
    except Exception as e:
        print(f"âŒ Erro no TF-IDF: {e}")

def main():
    print("ğŸ•µï¸ DEBUG VOCABULÃRIO - Investigando problema do 'brigadeiro'")
    print("=" * 60)
    
    test_vectorizer_steps()

if __name__ == "__main__":
    main()